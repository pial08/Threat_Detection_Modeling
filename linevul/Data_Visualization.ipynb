{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d040f7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "1.11.0+cu102\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(torch.__version__)\n",
    "foo = torch.tensor([1,2,3])\n",
    "foo = foo.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0a7eddc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Nov 30 15:30:55 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 470.141.03   Driver Version: 470.141.03   CUDA Version: 11.4     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0  On |                  N/A |\r\n",
      "| 23%   38C    P8    17W / 250W |   1450MiB / 11176MiB |      4%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  NVIDIA GeForce ...  Off  | 00000000:02:00.0 Off |                  N/A |\r\n",
      "| 23%   29C    P8     7W / 250W |     13MiB / 11178MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A      1358      G   /usr/lib/xorg/Xorg                 24MiB |\r\n",
      "|    0   N/A  N/A      1448      G   /usr/bin/gnome-shell               82MiB |\r\n",
      "|    0   N/A  N/A      1820      G   /usr/lib/xorg/Xorg                358MiB |\r\n",
      "|    0   N/A  N/A      1977      G   /usr/bin/gnome-shell               65MiB |\r\n",
      "|    0   N/A  N/A      2331      G   ...AAAAAAAAA= --shared-files       67MiB |\r\n",
      "|    0   N/A  N/A      3347      G   ...RendererForSitePerProcess       51MiB |\r\n",
      "|    0   N/A  N/A      3871      G   ...687164793183578521,131072      110MiB |\r\n",
      "|    0   N/A  N/A     20682      C   ...afis/anaconda3/bin/python      679MiB |\r\n",
      "|    0   N/A  N/A     27942      G   gnome-control-center                2MiB |\r\n",
      "|    1   N/A  N/A      1358      G   /usr/lib/xorg/Xorg                  4MiB |\r\n",
      "|    1   N/A  N/A      1820      G   /usr/lib/xorg/Xorg                  4MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa965e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../data/big-vul_dataset/train.csv')\n",
    "\n",
    "#df[\"flaw_line\"].notnull()\n",
    "\n",
    "#df = df[df['flaw_line'].notnull()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d35d2aa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>logits</th>\n",
       "      <th>y_trues</th>\n",
       "      <th>y_preds</th>\n",
       "      <th>index</th>\n",
       "      <th>num_flaw_lines</th>\n",
       "      <th>num_lines</th>\n",
       "      <th>flaw_line</th>\n",
       "      <th>processed_func</th>\n",
       "      <th>IoU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.464832</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>if (current_utterance_ &amp;&amp; !current_utterance...</td>\n",
       "      <td>void ExtensionTtsController::Stop() {\\n  if (c...</td>\n",
       "      <td>0.741117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>0.410566</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>(base::win::GetVersion() &lt; base::win::VE...</td>\n",
       "      <td>void EnableHighDPISupport() {\\nif (IsHighDPIEn...</td>\n",
       "      <td>0.682353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>0.444651</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>unsigned long resource_id, const GURL&amp; url...</td>\n",
       "      <td>WebPluginResourceClient* WebPluginDelegateImpl...</td>\n",
       "      <td>0.680233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>0.358002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>if (id.cluster &lt; 0 || id.proc &lt; 0) {</td>\n",
       "      <td>SchedulerObject::_continue(std::string key, st...</td>\n",
       "      <td>0.612903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>0.407127</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>// The navigation should commit in the pen...</td>\n",
       "      <td>void GoBackCrossSite() {\\nNavigationEntry* ent...</td>\n",
       "      <td>0.593023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>21</td>\n",
       "      <td>0.407962</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>GHashTable **o...</td>\n",
       "      <td>my_object_dict_of_dicts (MyObject *obj, GHashT...</td>\n",
       "      <td>0.539604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0.401694</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>const std...</td>\n",
       "      <td>static void CloudPrintInfoCallback(bool enable...</td>\n",
       "      <td>0.519231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>17</td>\n",
       "      <td>0.396940</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>{/~/    ExceptionCode ignoredExceptionCode;/~/...</td>\n",
       "      <td>static inline void removeElementPreservingChil...</td>\n",
       "      <td>0.462222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0.369835</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>if ((ctxt-&gt;context-&gt;node-&gt;type == XML_ATTR...</td>\n",
       "      <td>xmlXPathNextPrecedingInternal(xmlXPathParserCo...</td>\n",
       "      <td>0.380282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15</td>\n",
       "      <td>0.363747</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>return media_controls_view_-&gt;close_button_...</td>\n",
       "      <td>views::ImageButton* close_button() const {\\n  ...</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    logits  y_trues  y_preds  index  num_flaw_lines  num_lines  \\\n",
       "0           3  0.464832      1.0    False      3              16         18   \n",
       "1          25  0.410566      1.0    False     25               4          8   \n",
       "2          18  0.444651      1.0    False     18              14         16   \n",
       "3           8  0.358002      1.0    False      8               1         11   \n",
       "4          12  0.407127      1.0    False     12               4          9   \n",
       "5          21  0.407962      1.0    False     21               8          9   \n",
       "6           0  0.401694      1.0    False      0               3          5   \n",
       "7          17  0.396940      1.0    False     17              13         14   \n",
       "8           1  0.369835      1.0    False      1               3         30   \n",
       "9          15  0.363747      1.0    False     15               2          3   \n",
       "\n",
       "                                           flaw_line  \\\n",
       "0    if (current_utterance_ && !current_utterance...   \n",
       "1        (base::win::GetVersion() < base::win::VE...   \n",
       "2      unsigned long resource_id, const GURL& url...   \n",
       "3               if (id.cluster < 0 || id.proc < 0) {   \n",
       "4      // The navigation should commit in the pen...   \n",
       "5                                  GHashTable **o...   \n",
       "6                                       const std...   \n",
       "7  {/~/    ExceptionCode ignoredExceptionCode;/~/...   \n",
       "8      if ((ctxt->context->node->type == XML_ATTR...   \n",
       "9      return media_controls_view_->close_button_...   \n",
       "\n",
       "                                      processed_func       IoU  \n",
       "0  void ExtensionTtsController::Stop() {\\n  if (c...  0.741117  \n",
       "1  void EnableHighDPISupport() {\\nif (IsHighDPIEn...  0.682353  \n",
       "2  WebPluginResourceClient* WebPluginDelegateImpl...  0.680233  \n",
       "3  SchedulerObject::_continue(std::string key, st...  0.612903  \n",
       "4  void GoBackCrossSite() {\\nNavigationEntry* ent...  0.593023  \n",
       "5  my_object_dict_of_dicts (MyObject *obj, GHashT...  0.539604  \n",
       "6  static void CloudPrintInfoCallback(bool enable...  0.519231  \n",
       "7  static inline void removeElementPreservingChil...  0.462222  \n",
       "8  xmlXPathNextPrecedingInternal(xmlXPathParserCo...  0.380282  \n",
       "9  views::ImageButton* close_button() const {\\n  ...  0.200000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('result_df.csv')\n",
    "\n",
    "\n",
    "\n",
    "df.head(10)\n",
    "\n",
    "#df = df.sort_values(by=['IoU'], ascending=False)\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b339f0d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150908\n",
      "Len of new DF: 6613\n"
     ]
    }
   ],
   "source": [
    "print(len(df))\n",
    "df.head(50)\n",
    "\n",
    "#and len(row[\"processed_func\"].split(\" \")) <= 50\n",
    "new_df = pd.DataFrame()\n",
    "\n",
    "counter = 0\n",
    "for index, row in df.iterrows():\n",
    "    if row[\"target\"] == 1:# and len(row[\"processed_func\"].split(\" \")) <= 200:\n",
    "        new_df = new_df.append(row)\n",
    "        \n",
    "    counter += 1\n",
    "    #print(row['c1'], row['c2'])\n",
    "\n",
    "    \n",
    "new_df = new_df[new_df['flaw_line'].notnull()]\n",
    "print(\"Len of new DF:\", len(new_df))\n",
    "new_df.head()\n",
    "\n",
    "new_df.to_csv(\"mini_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ccfc677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        NaN\n",
      "1        NaN\n",
      "2        NaN\n",
      "3        NaN\n",
      "4        NaN\n",
      "        ... \n",
      "18859    NaN\n",
      "18860    NaN\n",
      "18861    NaN\n",
      "18862    NaN\n",
      "18863    NaN\n",
      "Name: flaw_line, Length: 18864, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flaw_line = df['flaw_line']\n",
    "flaw_line_index = df['flaw_line_index']\n",
    "print(flaw_line)\n",
    "flaw_line_index.iloc[4]\n",
    "#df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93f33583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15, 16, 17, 18]\n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from itertools import groupby\n",
    "\n",
    "def get_longest_list(lst):\n",
    "    return max(lst, key=len)\n",
    "\n",
    "data = [ 1,  4,5,6, 10, 15,16,17,18, 22, 25,26,27,28]\n",
    "\n",
    "def consequent(data):\n",
    "    finalList = []\n",
    "    for k, g in groupby(enumerate(data), lambda ix : ix[0] - ix[1]):\n",
    "        #print(list(map(itemgetter(1), g)))\n",
    "        finalList.append(list(map(itemgetter(1), g)))\n",
    "     \n",
    "    return get_longest_list(finalList)\n",
    "\n",
    "print(consequent(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d903131e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Tensor: tensor([0.1000, 0.2000, 0.4000, 0.5000])\n",
      "Target Tensor: tensor([0.0900, 0.2000, 0.3800, 0.5200])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-c69da371fcae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# compute the loss (mean squared error)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# output.backward()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1163\u001b[0;31m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[1;32m   1164\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m                                label_smoothing=self.label_smoothing)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   2994\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2995\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2996\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "# Import the required libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# define the input and target tensors\n",
    "input = torch.tensor([0.10, 0.20, 0.40, 0.50])\n",
    "target = torch.tensor([0.09, 0.2, 0.38, 0.52])\n",
    "\n",
    "# print input and target tensors\n",
    "print(\"Input Tensor:\", input)\n",
    "print(\"Target Tensor:\", target)\n",
    "\n",
    "# create a criterion to measure the mean squared error\n",
    "mse = nn.MSELoss()\n",
    "cet = nn.CrossEntropyLoss()\n",
    "# compute the loss (mean squared error)\n",
    "output = mse(input, target)\n",
    "output = cet(input, target)\n",
    "\n",
    "# output.backward()\n",
    "print(\"MSE loss:\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cd94766",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "import argparse\n",
    "import glob\n",
    "import logging\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import re\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, SequentialSampler, RandomSampler,TensorDataset\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from transformers import (WEIGHTS_NAME, AdamW, get_linear_schedule_with_warmup,\n",
    "                          RobertaConfig, RobertaForSequenceClassification, RobertaTokenizer)\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "from linevul_model import Model\n",
    "import pandas as pd\n",
    "# metrics\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.metrics import auc\n",
    "# model reasoning\n",
    "from captum.attr import LayerIntegratedGradients, DeepLift, DeepLiftShap, GradientShap, Saliency\n",
    "# word-level tokenizer\n",
    "from tokenizers import Tokenizer\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cd29dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputFeatures(object):\n",
    "    \"\"\"A single training/test features for a example.\"\"\"\n",
    "    def __init__(self,\n",
    "                 input_tokens,\n",
    "                 input_ids,\n",
    "                 label):\n",
    "        self.input_tokens = input_tokens\n",
    "        self.input_ids = input_ids\n",
    "        self.label=label\n",
    "        \n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, tokenizer, args, file_type=\"train\"):\n",
    "        if file_type == \"train\":\n",
    "            file_path = args.train_data_file\n",
    "        elif file_type == \"eval\":\n",
    "            file_path = args.eval_data_file\n",
    "        elif file_type == \"test\":\n",
    "            file_path = args.test_data_file\n",
    "        self.examples = []\n",
    "        df = pd.read_csv(file_path)\n",
    "        funcs = df[\"processed_func\"].tolist()\n",
    "        labels = df[\"target\"].tolist()\n",
    "        for i in tqdm(range(len(funcs))):\n",
    "            self.examples.append(convert_examples_to_features(funcs[i], labels[i], tokenizer, args))\n",
    "        if file_type == \"train\":\n",
    "            for example in self.examples[:3]:\n",
    "                    logger.info(\"*** Example ***\")\n",
    "                    logger.info(\"label: {}\".format(example.label))\n",
    "                    logger.info(\"input_tokens: {}\".format([x.replace('\\u0120','_') for x in example.input_tokens]))\n",
    "                    logger.info(\"input_ids: {}\".format(' '.join(map(str, example.input_ids))))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, i):       \n",
    "        return torch.tensor(self.examples[i].input_ids),torch.tensor(self.examples[i].label)\n",
    "\n",
    "\n",
    "def convert_examples_to_features(func, label, tokenizer, args):\n",
    "    if args.use_word_level_tokenizer:\n",
    "        encoded = tokenizer.encode(func)\n",
    "        encoded = encoded.ids\n",
    "        if len(encoded) > 510:\n",
    "            encoded = encoded[:510]\n",
    "        encoded.insert(0, 0)\n",
    "        encoded.append(2)\n",
    "        if len(encoded) < 512:\n",
    "            padding = 512 - len(encoded)\n",
    "            for _ in range(padding):\n",
    "                encoded.append(1)\n",
    "        source_ids = encoded\n",
    "        source_tokens = []\n",
    "        return InputFeatures(source_tokens, source_ids, label)\n",
    "    # source\n",
    "    code_tokens = tokenizer.tokenize(str(func))[:args.block_size-2]\n",
    "    source_tokens = [tokenizer.cls_token] + code_tokens + [tokenizer.sep_token]\n",
    "    source_ids = tokenizer.convert_tokens_to_ids(source_tokens)\n",
    "    padding_length = args.block_size - len(source_ids)\n",
    "    source_ids += [tokenizer.pad_token_id] * padding_length\n",
    "    return InputFeatures(source_tokens, source_ids, label)\n",
    "\n",
    "def set_seed(args):\n",
    "    random.seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    if args.n_gpu > 0:\n",
    "        torch.cuda.manual_seed_all(args.seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d74ff61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "## parameters\n",
    "parser.add_argument(\"--train_data_file\", default=\"../data/big-vul_dataset/train.csv\", type=str, required=False,\n",
    "                    help=\"The input training data file (a csv file).\")\n",
    "parser.add_argument(\"--output_dir\", default=\"./saved_models\", type=str, required=False,\n",
    "                    help=\"The output directory where the model predictions and checkpoints will be written.\")\n",
    "parser.add_argument(\"--model_type\", default=\"roberta\", type=str,\n",
    "                    help=\"The model architecture to be fine-tuned.\")\n",
    "parser.add_argument(\"--block_size\", default=512, type=int,\n",
    "                    help=\"Optional input sequence length after tokenization.\"\n",
    "                         \"The training dataset will be truncated in block of this size for training.\"\n",
    "                         \"Default to the model max input length for single sentence inputs (take into account special tokens).\")\n",
    "parser.add_argument(\"--eval_data_file\", default=\"../data/big-vul_dataset/val.csv\", type=str,\n",
    "                    help=\"An optional input evaluation data file to evaluate the perplexity on (a text file).\")\n",
    "parser.add_argument(\"--test_data_file\", default=\"../data/big-vul_dataset/test.csv\", type=str,\n",
    "                    help=\"An optional input evaluation data file to evaluate the perplexity on (a text file).\")\n",
    "parser.add_argument(\"--model_name\", default=\"12heads_linevul_model.bin\", type=str,\n",
    "                    help=\"Saved model name.\")\n",
    "parser.add_argument(\"--model_name_or_path\", default=\"microsoft/codebert-base\", type=str,\n",
    "                    help=\"The model checkpoint for weights initialization.\")\n",
    "parser.add_argument(\"--config_name\", default=\"\", type=str,\n",
    "                    help=\"Optional pretrained config name or path if not the same as model_name_or_path\")\n",
    "parser.add_argument(\"--use_non_pretrained_model\", action='store_true', default=False,\n",
    "                    help=\"Whether to use non-pretrained model.\")\n",
    "parser.add_argument(\"--tokenizer_name\", default=\"microsoft/codebert-base\", type=str,\n",
    "                    help=\"Optional pretrained tokenizer name or path if not the same as model_name_or_path\")\n",
    "parser.add_argument(\"--code_length\", default=256, type=int,\n",
    "                    help=\"Optional Code input sequence length after tokenization.\") \n",
    "\n",
    "parser.add_argument(\"--do_train\", action='store_true',\n",
    "                    help=\"Whether to run training.\")\n",
    "parser.add_argument(\"--do_eval\", action='store_true',\n",
    "                    help=\"Whether to run eval on the dev set.\")\n",
    "parser.add_argument(\"--do_test\", action='store_true',\n",
    "                    help=\"Whether to run eval on the dev set.\")\n",
    "\n",
    "parser.add_argument(\"--evaluate_during_training\", action='store_true',\n",
    "                    help=\"Run evaluation during training at each logging step.\")\n",
    "parser.add_argument(\"--do_local_explanation\", default=False, action='store_true',\n",
    "                    help=\"Whether to do local explanation. \") \n",
    "parser.add_argument(\"--reasoning_method\", default=\"all\", type=str,\n",
    "                    help=\"Should be one of 'attention', 'shap', 'lime', 'lig'\")\n",
    "\n",
    "parser.add_argument(\"--train_batch_size\", default=1, type=int,\n",
    "                    help=\"Batch size per GPU/CPU for training.\")\n",
    "parser.add_argument(\"--eval_batch_size\", default=256, type=int,\n",
    "                    help=\"Batch size per GPU/CPU for evaluation.\")\n",
    "parser.add_argument('--gradient_accumulation_steps', type=int, default=1,\n",
    "                    help=\"Number of updates steps to accumulate before performing a backward/update pass.\")\n",
    "parser.add_argument(\"--learning_rate\", default=5e-5, type=float,\n",
    "                    help=\"The initial learning rate for Adam.\")\n",
    "parser.add_argument(\"--weight_decay\", default=0.0, type=float,\n",
    "                    help=\"Weight deay if we apply some.\")\n",
    "parser.add_argument(\"--adam_epsilon\", default=1e-8, type=float,\n",
    "                    help=\"Epsilon for Adam optimizer.\")\n",
    "parser.add_argument(\"--max_grad_norm\", default=1.0, type=float,\n",
    "                    help=\"Max gradient norm.\")\n",
    "parser.add_argument(\"--max_steps\", default=-1, type=int,\n",
    "                    help=\"If > 0: set total number of training steps to perform. Override num_train_epochs.\")\n",
    "parser.add_argument(\"--warmup_steps\", default=0, type=int,\n",
    "                    help=\"Linear warmup over warmup_steps.\")\n",
    "parser.add_argument('--seed', type=int, default=42,\n",
    "                    help=\"random seed for initialization\")\n",
    "parser.add_argument('--epochs', type=int, default=1,\n",
    "                    help=\"training epochs\")\n",
    "# RQ2\n",
    "parser.add_argument(\"--effort_at_top_k\", default=0.2, type=float,\n",
    "                    help=\"Effort@TopK%Recall: effort at catching top k percent of vulnerable lines\")\n",
    "parser.add_argument(\"--top_k_recall_by_lines\", default=0.01, type=float,\n",
    "                    help=\"Recall@TopK percent, sorted by line scores\")\n",
    "parser.add_argument(\"--top_k_recall_by_pred_prob\", default=0.2, type=float,\n",
    "                    help=\"Recall@TopK percent, sorted by prediction probabilities\")\n",
    "\n",
    "parser.add_argument(\"--do_sorting_by_line_scores\", default=True, action='store_true',\n",
    "                    help=\"Whether to do sorting by line scores.\")\n",
    "parser.add_argument(\"--do_sorting_by_pred_prob\", default=False, action='store_true',\n",
    "                    help=\"Whether to do sorting by prediction probabilities.\")\n",
    "# RQ3 - line-level evaluation\n",
    "parser.add_argument('--top_k_constant', type=int, default=10,\n",
    "                    help=\"Top-K Accuracy constant\")\n",
    "# num of attention heads\n",
    "parser.add_argument('--num_attention_heads', type=int, default=12,\n",
    "                    help=\"number of attention heads used in CodeBERT\")\n",
    "# raw predictions\n",
    "parser.add_argument(\"--write_raw_preds\", default=False, action='store_true',\n",
    "                        help=\"Whether to write raw predictions on test data.\")\n",
    "# word-level tokenizer\n",
    "parser.add_argument(\"--use_word_level_tokenizer\", default=False, action='store_true',\n",
    "                    help=\"Whether to use word-level tokenizer.\")\n",
    "# bpe non-pretrained tokenizer\n",
    "parser.add_argument(\"--use_non_pretrained_tokenizer\", default=False, action='store_true',\n",
    "                    help=\"Whether to use non-pretrained bpe tokenizer.\")\n",
    "#args = parser.parse_args()\n",
    "\n",
    "#args = parser.parse_args(\"AAA --file run.sh\".split())\n",
    "args = parser.parse_args(args=[])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "017a983d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "microsoft/codebert-base\n"
     ]
    }
   ],
   "source": [
    "print(args.tokenizer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6037c93a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/05/2022 17:13:43 - WARNING - __main__ -   device: cuda, n_gpu: 2\n",
      "Some weights of the model checkpoint at microsoft/codebert-base were not used when initializing RobertaForSequenceClassification: ['pooler.dense.weight', 'pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/codebert-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "12/05/2022 17:13:47 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, block_size=512, code_length=256, config_name='', device=device(type='cuda'), do_eval=False, do_local_explanation=False, do_sorting_by_line_scores=True, do_sorting_by_pred_prob=False, do_test=False, do_train=False, effort_at_top_k=0.2, epochs=1, eval_batch_size=256, eval_data_file='../data/big-vul_dataset/val.csv', evaluate_during_training=False, gradient_accumulation_steps=1, learning_rate=5e-05, max_grad_norm=1.0, max_steps=-1, model_name='12heads_linevul_model.bin', model_name_or_path='microsoft/codebert-base', model_type='roberta', n_gpu=2, num_attention_heads=12, output_dir='./saved_models', reasoning_method='all', seed=42, test_data_file='../data/big-vul_dataset/test.csv', tokenizer_name='microsoft/codebert-base', top_k_constant=10, top_k_recall_by_lines=0.01, top_k_recall_by_pred_prob=0.2, train_batch_size=1, train_data_file='../data/big-vul_dataset/train.csv', use_non_pretrained_model=False, use_non_pretrained_tokenizer=False, use_word_level_tokenizer=False, warmup_steps=0, weight_decay=0.0, write_raw_preds=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing final model ... RobertaModel(\n",
      "  (embeddings): RobertaEmbeddings(\n",
      "    (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
      "    (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "    (token_type_embeddings): Embedding(1, 768)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): RobertaEncoder(\n",
      "    (layer): ModuleList(\n",
      "      (0): RobertaLayer(\n",
      "        (attention): RobertaAttention(\n",
      "          (self): RobertaSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RobertaSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RobertaIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): RobertaOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): RobertaLayer(\n",
      "        (attention): RobertaAttention(\n",
      "          (self): RobertaSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RobertaSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RobertaIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): RobertaOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (2): RobertaLayer(\n",
      "        (attention): RobertaAttention(\n",
      "          (self): RobertaSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RobertaSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RobertaIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): RobertaOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (3): RobertaLayer(\n",
      "        (attention): RobertaAttention(\n",
      "          (self): RobertaSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RobertaSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RobertaIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): RobertaOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (4): RobertaLayer(\n",
      "        (attention): RobertaAttention(\n",
      "          (self): RobertaSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RobertaSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RobertaIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): RobertaOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (5): RobertaLayer(\n",
      "        (attention): RobertaAttention(\n",
      "          (self): RobertaSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RobertaSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RobertaIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): RobertaOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (6): RobertaLayer(\n",
      "        (attention): RobertaAttention(\n",
      "          (self): RobertaSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RobertaSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RobertaIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): RobertaOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (7): RobertaLayer(\n",
      "        (attention): RobertaAttention(\n",
      "          (self): RobertaSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RobertaSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RobertaIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): RobertaOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (8): RobertaLayer(\n",
      "        (attention): RobertaAttention(\n",
      "          (self): RobertaSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RobertaSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RobertaIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): RobertaOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (9): RobertaLayer(\n",
      "        (attention): RobertaAttention(\n",
      "          (self): RobertaSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RobertaSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RobertaIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): RobertaOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (10): RobertaLayer(\n",
      "        (attention): RobertaAttention(\n",
      "          (self): RobertaSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RobertaSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RobertaIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): RobertaOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (11): RobertaLayer(\n",
      "        (attention): RobertaAttention(\n",
      "          (self): RobertaSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RobertaSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RobertaIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): RobertaOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "args.n_gpu = torch.cuda.device_count()\n",
    "args.device = device\n",
    "# Setup logging\n",
    "logging.basicConfig(format='%(asctime)s - %(levelname)s - %(name)s -   %(message)s',datefmt='%m/%d/%Y %H:%M:%S',level=logging.INFO)\n",
    "logger.warning(\"device: %s, n_gpu: %s\",device, args.n_gpu,)\n",
    "# Set seed\n",
    "set_seed(args)\n",
    "config = RobertaConfig.from_pretrained(args.model_name_or_path)\n",
    "config.num_labels = 1\n",
    "config.num_attention_heads = args.num_attention_heads\n",
    "if args.use_word_level_tokenizer:\n",
    "    print('using wordlevel tokenizer!')\n",
    "    tokenizer = Tokenizer.from_file('./word_level_tokenizer/wordlevel.json')\n",
    "elif args.use_non_pretrained_tokenizer:\n",
    "    tokenizer = RobertaTokenizer(vocab_file=\"bpe_tokenizer/bpe_tokenizer-vocab.json\",\n",
    "                                 merges_file=\"bpe_tokenizer/bpe_tokenizer-merges.txt\")\n",
    "else:\n",
    "    tokenizer = RobertaTokenizer.from_pretrained(args.tokenizer_name)\n",
    "if args.use_non_pretrained_model:\n",
    "    model = RobertaForSequenceClassification(config=config)        \n",
    "else:\n",
    "    model = RobertaForSequenceClassification.from_pretrained(args.model_name_or_path, config=config, ignore_mismatched_sizes=True)    \n",
    "\n",
    "#print(\"printing original model ...\", model)\n",
    "\n",
    "model = Model(model, config, tokenizer, args)\n",
    "print(\"printing final model ...\", model.encoder.roberta)\n",
    "logger.info(\"Training/evaluation parameters %s\", args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a04325e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_result_df(logits, y_trues, y_preds, args):\n",
    "    df = pd.read_csv(args.test_data_file)\n",
    "    all_num_lines = []\n",
    "    all_processed_func = df[\"processed_func\"].tolist()\n",
    "    for func in all_processed_func:\n",
    "        all_num_lines.append(get_num_lines(func))\n",
    "    flaw_line_indices = df[\"flaw_line_index\"].tolist()\n",
    "    all_num_flaw_lines = []\n",
    "    total_flaw_lines = 0\n",
    "    for indices in flaw_line_indices:\n",
    "        if isinstance(indices, str):\n",
    "            indices = indices.split(\",\")\n",
    "            num_flaw_lines = len(indices)\n",
    "            total_flaw_lines += num_flaw_lines\n",
    "        else:\n",
    "            num_flaw_lines = 0\n",
    "        all_num_flaw_lines.append(num_flaw_lines)\n",
    "    assert len(logits) == len(y_trues) == len(y_preds) == len(all_num_flaw_lines)\n",
    "    return pd.DataFrame({\"logits\": logits, \"y_trues\": y_trues, \"y_preds\": y_preds, \n",
    "                         \"index\": list(range(len(logits))), \"num_flaw_lines\": all_num_flaw_lines, \"num_lines\": all_num_lines, \n",
    "                         \"flaw_line\": df[\"flaw_line\"], \"processed_func\": df[\"processed_func\"]})\n",
    "\n",
    "def write_raw_preds_csv(args, y_preds):\n",
    "    df = pd.read_csv(args.test_data_file)\n",
    "    df[\"raw_preds\"] = y_preds\n",
    "    df.to_csv(\"./results/raw_preds.csv\", index=False)\n",
    "\n",
    "def get_num_lines(func):\n",
    "    func = func.split(\"\\n\")\n",
    "    func = [line for line in func if len(line) > 0]\n",
    "    return len(func)\n",
    "\n",
    "def get_line_statistics(result_df):\n",
    "    total_lines = sum(result_df[\"num_lines\"].tolist())\n",
    "    total_flaw_lines = sum(result_df[\"num_flaw_lines\"].tolist())\n",
    "    return total_lines, total_flaw_lines\n",
    "\n",
    "def rank_lines(all_lines_score_with_label, is_attention, ascending_ranking):\n",
    "    # flatten the list\n",
    "    all_lines_score_with_label = [line for lines in all_lines_score_with_label for line in lines]\n",
    "    if is_attention:\n",
    "        all_scores = [line[0].item() for line in all_lines_score_with_label]\n",
    "    else:\n",
    "        all_scores = [line[0] for line in all_lines_score_with_label]\n",
    "    all_labels = [line[1] for line in all_lines_score_with_label]\n",
    "    rank_df = pd.DataFrame({\"score\": all_scores, \"label\": all_labels})\n",
    "    rank_df = rank_dataframe(rank_df, \"score\", ascending_ranking)\n",
    "    return len(rank_df), rank_df\n",
    "\n",
    "def rank_dataframe(df, rank_by: str, ascending: bool):\n",
    "    df = df.sort_values(by=[rank_by], ascending=ascending)\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def top_k_effort(rank_df, sum_lines, sum_flaw_lines, top_k_loc, label_col_name=\"label\"):\n",
    "    target_flaw_line = int(sum_flaw_lines * top_k_loc)\n",
    "    caught_flaw_line = 0\n",
    "    inspected_line = 0\n",
    "    for i in range(len(rank_df)):\n",
    "        inspected_line += 1\n",
    "        if rank_df[label_col_name][i] == 1:\n",
    "            caught_flaw_line += 1\n",
    "        if target_flaw_line == caught_flaw_line:\n",
    "            break\n",
    "    effort = round(inspected_line / sum_lines, 4)\n",
    "    return effort, inspected_line\n",
    "\n",
    "def top_k_effort_pred_prob(rank_df, sum_lines, sum_flaw_lines, top_k_loc, label_col_name=\"y_preds\"):\n",
    "    target_flaw_line = int(sum_flaw_lines * top_k_loc)\n",
    "    caught_flaw_line = 0\n",
    "    inspected_line = 0\n",
    "    for i in range(len(rank_df)):\n",
    "        inspected_line += rank_df[\"num_lines\"][i]\n",
    "        if rank_df[label_col_name][i] == 1 or rank_df[label_col_name][i] is True:\n",
    "            caught_flaw_line += rank_df[\"num_flaw_lines\"][i]\n",
    "        if caught_flaw_line >= target_flaw_line:\n",
    "            break\n",
    "    effort = round(inspected_line / sum_lines, 4)\n",
    "    return effort, inspected_line\n",
    "\n",
    "def top_k_recall(pos_rank_df, neg_rank_df, sum_lines, sum_flaw_lines, top_k_loc):\n",
    "    target_inspected_line = int(sum_lines * top_k_loc)\n",
    "    caught_flaw_line = 0\n",
    "    inspected_line = 0\n",
    "    inspect_neg_lines = True\n",
    "    for i in range(len(pos_rank_df)):\n",
    "        inspected_line += 1\n",
    "        if inspected_line > target_inspected_line:\n",
    "            inspect_neg_lines = False\n",
    "            break\n",
    "        if pos_rank_df[\"label\"][i] == 1 or pos_rank_df[\"label\"][i] is True:\n",
    "            caught_flaw_line += 1\n",
    "    if inspect_neg_lines:\n",
    "        for i in range(len(neg_rank_df)):\n",
    "            inspected_line += 1\n",
    "            if inspected_line > target_inspected_line:\n",
    "                break\n",
    "            if neg_rank_df[\"label\"][i] == 1 or neg_rank_df[\"label\"][i] is True:\n",
    "                caught_flaw_line += 1\n",
    "    return round(caught_flaw_line / sum_flaw_lines, 4)\n",
    "\n",
    "def top_k_recall_pred_prob(rank_df, sum_lines: int, sum_flaw_lines: int, top_k_loc: float, label_col_name=\"y_preds\"):\n",
    "    target_inspected_line = int(sum_lines * top_k_loc)\n",
    "    caught_flaw_line = 0\n",
    "    inspected_line = 0\n",
    "    for i in range(len(rank_df)):\n",
    "        inspected_line += rank_df[\"num_lines\"][i]\n",
    "        if inspected_line > target_inspected_line:\n",
    "            break\n",
    "        if rank_df[label_col_name][i] == 1 or rank_df[label_col_name][i] is True:\n",
    "            caught_flaw_line += rank_df[\"num_flaw_lines\"][i]\n",
    "    return round(caught_flaw_line / sum_flaw_lines, 4)\n",
    "\n",
    "def summarize_attributions(attributions):\n",
    "    attributions = attributions.sum(dim=-1).squeeze(0)\n",
    "    attributions = attributions / torch.norm(attributions)\n",
    "    return attributions\n",
    "\n",
    "def create_ref_input_ids(input_ids, ref_token_id, sep_token_id, cls_token_id):\n",
    "    seq_length = input_ids.size(1)\n",
    "    ref_input_ids = [cls_token_id] + [ref_token_id] * (seq_length-2) + [sep_token_id]\n",
    "    return torch.tensor([ref_input_ids])\n",
    "\n",
    "def line_level_localization_tp(flaw_lines: str, tokenizer, model, mini_batch, original_func: str, args, top_k_loc: list, top_k_constant: list, reasoning_method: str, index: int, write_invalid_data: bool):\n",
    "    # function for captum LIG.\n",
    "    def predict(input_ids):\n",
    "        return model(input_ids=input_ids)[0]\n",
    "\n",
    "    def lig_forward(input_ids):\n",
    "        logits = model(input_ids=input_ids)[0]\n",
    "        y_pred = 1 # for positive attribution, y_pred = 0 for negative attribution\n",
    "        pred_prob = logits[y_pred].unsqueeze(-1)\n",
    "        return pred_prob\n",
    "\n",
    "    flaw_line_seperator = \"/~/\"\n",
    "    (input_ids, labels) = mini_batch\n",
    "    ids = input_ids[0].detach().tolist()\n",
    "    all_tokens = tokenizer.convert_ids_to_tokens(ids)\n",
    "    all_tokens = [token.replace(\"\", \"\") for token in all_tokens]\n",
    "    all_tokens = [token.replace(\"\", \"\") for token in all_tokens]\n",
    "    original_lines = ''.join(all_tokens).split(\"\")\n",
    "\n",
    "    # flaw line verification\n",
    "    # get flaw tokens ground truth\n",
    "    flaw_lines = get_all_flaw_lines(flaw_lines=flaw_lines, flaw_line_seperator=flaw_line_seperator)\n",
    "    flaw_tokens_encoded = encode_all_lines(all_lines=flaw_lines, tokenizer=tokenizer)\n",
    "    verified_flaw_lines = []\n",
    "    do_explanation = False\n",
    "    for i in range(len(flaw_tokens_encoded)):\n",
    "        encoded_flaw = ''.join(flaw_tokens_encoded[i])\n",
    "        encoded_all = ''.join(all_tokens)\n",
    "        if encoded_flaw in encoded_all:\n",
    "            verified_flaw_lines.append(flaw_tokens_encoded[i])\n",
    "            do_explanation = True\n",
    "\n",
    "    # do explanation if at least one flaw line exist in the encoded input\n",
    "    if do_explanation:\n",
    "        if reasoning_method == \"attention\":\n",
    "            # attentions: a tuple with of one Tensor with 4D shape (batch_size, num_heads, sequence_length, sequence_length)\n",
    "            input_ids = input_ids.to(args.device)\n",
    "            prob, attentions = model(input_ids=input_ids, output_attentions=True)\n",
    "            # take from tuple then take out mini-batch attention values\n",
    "            attentions = attentions[0][0]\n",
    "            #print(\"Shape of attention\", attentions.shape)\n",
    "            attention = None\n",
    "            # go into the layer\n",
    "            for i in range(len(attentions)):\n",
    "                layer_attention = attentions[i]\n",
    "                # summerize the values of each token dot other tokens\n",
    "                layer_attention = sum(layer_attention)\n",
    "                if attention is None:\n",
    "                    attention = layer_attention\n",
    "                else:\n",
    "                    attention += layer_attention\n",
    "            # clean att score for <s> and </s>\n",
    "            attention = clean_special_token_values(attention, padding=True)\n",
    "            # attention should be 1D tensor with seq length representing each token's attention value\n",
    "            word_att_scores = get_word_att_scores(all_tokens=all_tokens, att_scores=attention)\n",
    "            #print(\"Word attention scores ...\", word_att_scores)\n",
    "            all_lines_score, flaw_line_indices = get_all_lines_score(word_att_scores, verified_flaw_lines)\n",
    "            #print(\"all lines score\", all_lines_score)\n",
    "            # return if no flaw lines exist\n",
    "            if len(flaw_line_indices) == 0:\n",
    "                return \"NA\"\n",
    "            total_lines, num_of_flaw_lines, all_correctly_predicted_flaw_lines, min_clean_lines_inspected, max_clean_lines_inspected, all_correctly_localized_func, top_10_correct_idx, top_10_not_correct_idx \\\n",
    "            = \\\n",
    "            line_level_evaluation(all_lines_score=all_lines_score, flaw_line_indices=flaw_line_indices, top_k_loc=top_k_loc, top_k_constant=top_k_constant, true_positive_only=True, index=index)\n",
    "        elif reasoning_method == \"lig\":\n",
    "            ref_token_id, sep_token_id, cls_token_id = tokenizer.pad_token_id, tokenizer.sep_token_id, tokenizer.cls_token_id\n",
    "            ref_input_ids = create_ref_input_ids(input_ids, ref_token_id, sep_token_id, cls_token_id)\n",
    "            # send data to device\n",
    "            input_ids = input_ids.to(args.device)\n",
    "            labels = labels.to(args.device)\n",
    "            ref_input_ids = ref_input_ids.to(args.device)\n",
    "            lig = LayerIntegratedGradients(lig_forward, model.module.encoder.roberta.embeddings)\n",
    "            #print(input_ids.shape, ref_input_ids.shape)\n",
    "            attributions, delta = lig.attribute(inputs=input_ids,\n",
    "                                                baselines=ref_input_ids,\n",
    "                                                internal_batch_size=1,\n",
    "                                                return_convergence_delta=True)\n",
    "            score = predict(input_ids)\n",
    "            \n",
    "            pred_idx = torch.argmax(score).cpu().numpy()\n",
    "            pred_prob = score[pred_idx]\n",
    "            attributions_sum = summarize_attributions(attributions)        \n",
    "            attr_scores = attributions_sum.tolist()\n",
    "            # each token should have one score\n",
    "            assert len(all_tokens) == len(attr_scores)\n",
    "            # store tokens and attr scores together in a list of tuple [(token, attr_score)]\n",
    "            word_attr_scores = get_word_att_scores(all_tokens=all_tokens, att_scores=attr_scores)\n",
    "            # remove <s>, </s>, <unk>, <pad>\n",
    "            word_attr_scores = clean_word_attr_scores(word_attr_scores=word_attr_scores)\n",
    "            all_lines_score, flaw_line_indices = get_all_lines_score(word_attr_scores, verified_flaw_lines)\n",
    "            # return if no flaw lines exist\n",
    "            if len(flaw_line_indices) == 0:\n",
    "                return \"NA\"\n",
    "            total_lines, num_of_flaw_lines, all_correctly_predicted_flaw_lines, min_clean_lines_inspected, max_clean_lines_inspected, all_correctly_localized_func, top_10_correct_idx, top_10_not_correct_idx \\\n",
    "             = \\\n",
    "            line_level_evaluation(all_lines_score=all_lines_score, flaw_line_indices=flaw_line_indices, top_k_loc=top_k_loc, top_k_constant=top_k_constant, true_positive_only=True, index=index)\n",
    "        elif reasoning_method == \"deeplift\" or \\\n",
    "             reasoning_method == \"deeplift_shap\" or \\\n",
    "             reasoning_method == \"gradient_shap\" or \\\n",
    "             reasoning_method == \"saliency\":\n",
    "            # send data to device\n",
    "            input_ids = input_ids.to(args.device)\n",
    "            input_embed = model.module.encoder.roberta.embeddings(input_ids).to(args.device)\n",
    "            if reasoning_method == \"deeplift\":\n",
    "                #baselines = torch.randn(1, 512, 768, requires_grad=True).to(args.device)\n",
    "                baselines = torch.zeros(1, 512, 768, requires_grad=True).to(args.device)\n",
    "                reasoning_model = DeepLift(model)\n",
    "            elif reasoning_method == \"deeplift_shap\":\n",
    "                #baselines = torch.randn(16, 512, 768, requires_grad=True).to(args.device)\n",
    "                baselines = torch.zeros(16, 512, 768, requires_grad=True).to(args.device)\n",
    "                reasoning_model = DeepLiftShap(model)\n",
    "            elif reasoning_method == \"gradient_shap\":\n",
    "                #baselines = torch.randn(16, 512, 768, requires_grad=True).to(args.device)\n",
    "                baselines = torch.zeros(16, 512, 768, requires_grad=True).to(args.device)\n",
    "                reasoning_model = GradientShap(model)\n",
    "            elif reasoning_method == \"saliency\":\n",
    "                reasoning_model = Saliency(model)\n",
    "            # attributions -> [1, 512, 768]\n",
    "            if reasoning_method == \"saliency\":\n",
    "                attributions = reasoning_model.attribute(input_embed, target=1)\n",
    "            else:\n",
    "                attributions = reasoning_model.attribute(input_embed, baselines=baselines, target=1)\n",
    "            attributions_sum = summarize_attributions(attributions)        \n",
    "            attr_scores = attributions_sum.tolist()\n",
    "            # each token should have one score\n",
    "            assert len(all_tokens) == len(attr_scores)\n",
    "            # store tokens and attr scores together in a list of tuple [(token, attr_score)]\n",
    "            word_attr_scores = get_word_att_scores(all_tokens=all_tokens, att_scores=attr_scores)\n",
    "            # remove <s>, </s>, <unk>, <pad>\n",
    "            word_attr_scores = clean_word_attr_scores(word_attr_scores=word_attr_scores)\n",
    "            all_lines_score, flaw_line_indices = get_all_lines_score(word_attr_scores, verified_flaw_lines)\n",
    "            # return if no flaw lines exist\n",
    "            if len(flaw_line_indices) == 0:\n",
    "                return \"NA\"\n",
    "            total_lines, num_of_flaw_lines, all_correctly_predicted_flaw_lines, min_clean_lines_inspected, max_clean_lines_inspected, all_correctly_localized_func, top_10_correct_idx, top_10_not_correct_idx \\\n",
    "             = \\\n",
    "            line_level_evaluation(all_lines_score=all_lines_score, flaw_line_indices=flaw_line_indices, top_k_loc=top_k_loc, top_k_constant=top_k_constant, true_positive_only=True, index=index)        \n",
    "      \n",
    "        results = {\"total_lines\": total_lines,\n",
    "                    \"num_of_flaw_lines\": num_of_flaw_lines,\n",
    "                    \"all_correctly_predicted_flaw_lines\": all_correctly_predicted_flaw_lines,\n",
    "                    \"all_correctly_localized_function\": all_correctly_localized_func,\n",
    "                    \"min_clean_lines_inspected\": min_clean_lines_inspected,\n",
    "                    \"max_clean_lines_inspected\": max_clean_lines_inspected,\n",
    "                    \"top_10_correct_idx\": top_10_correct_idx,\n",
    "                    \"top_10_not_correct_idx\": top_10_not_correct_idx}\n",
    "        #print(results)\n",
    "        return results\n",
    "    else:\n",
    "        if write_invalid_data:\n",
    "            with open(\"../invalid_data/invalid_line_lev_data.txt\", \"a\") as f:\n",
    "                f.writelines(\"--- ALL TOKENS ---\")\n",
    "                f.writelines(\"\\n\")\n",
    "                alltok = ''.join(all_tokens)\n",
    "                alltok = alltok.split(\"\")\n",
    "                for tok in alltok:\n",
    "                    f.writelines(tok)\n",
    "                    f.writelines(\"\\n\")\n",
    "                f.writelines(\"--- FLAW ---\")\n",
    "                f.writelines(\"\\n\")\n",
    "                for i in range(len(flaw_tokens_encoded)):\n",
    "                    f.writelines(''.join(flaw_tokens_encoded[i]))\n",
    "                    f.writelines(\"\\n\")\n",
    "                f.writelines(\"\\n\")\n",
    "                f.writelines(\"\\n\")\n",
    "    # if no flaw line exist in the encoded input\n",
    "    return \"NA\"\n",
    "\n",
    "def line_level_localization(flaw_lines: str, tokenizer, model, mini_batch, original_func: str, args,\n",
    "                            top_k_loc: list, top_k_constant: list, reasoning_method: str, index: int):\n",
    "    # function for captum LIG.\n",
    "    def predict(input_ids):\n",
    "        return model(input_ids=input_ids)[0]\n",
    "\n",
    "    def lig_forward(input_ids):\n",
    "        logits = model(input_ids=input_ids)[0]\n",
    "        y_pred = 1 # for positive attribution, y_pred = 0 for negative attribution\n",
    "        pred_prob = logits[y_pred].unsqueeze(-1)\n",
    "        return pred_prob\n",
    "\n",
    "    flaw_line_seperator = \"/~/\"\n",
    "    (input_ids, labels) = mini_batch\n",
    "    ids = input_ids[0].detach().tolist()\n",
    "    all_tokens = tokenizer.convert_ids_to_tokens(ids)\n",
    "    all_tokens = [token.replace(\"\", \"\") for token in all_tokens]\n",
    "    all_tokens = [token.replace(\"\", \"\") for token in all_tokens]\n",
    "    original_lines = ''.join(all_tokens).split(\"\")\n",
    "\n",
    "    # flaw line verification\n",
    "    # get flaw tokens ground truth\n",
    "    flaw_lines = get_all_flaw_lines(flaw_lines=flaw_lines, flaw_line_seperator=flaw_line_seperator)\n",
    "    flaw_tokens_encoded = encode_all_lines(all_lines=flaw_lines, tokenizer=tokenizer)\n",
    "    verified_flaw_lines = []\n",
    "    for i in range(len(flaw_tokens_encoded)):\n",
    "        encoded_flaw = ''.join(flaw_tokens_encoded[i])\n",
    "        encoded_all = ''.join(all_tokens)\n",
    "        if encoded_flaw in encoded_all:\n",
    "            verified_flaw_lines.append(flaw_tokens_encoded[i])\n",
    "\n",
    "    if reasoning_method == \"attention\":\n",
    "        # attentions: a tuple with of one Tensor with 4D shape (batch_size, num_heads, sequence_length, sequence_length)\n",
    "        input_ids = input_ids.to(args.device)\n",
    "        model.eval()\n",
    "        model.to(args.device)\n",
    "        with torch.no_grad():\n",
    "            prob, attentions = model(input_ids=input_ids, output_attentions=True)\n",
    "        # take from tuple then take out mini-batch attention values\n",
    "        attentions = attentions[0][0]\n",
    "        attention = None\n",
    "        # go into the layer\n",
    "        for i in range(len(attentions)):\n",
    "            layer_attention = attentions[i]\n",
    "            # summerize the values of each token dot other tokens\n",
    "            layer_attention = sum(layer_attention)\n",
    "            if attention is None:\n",
    "                attention = layer_attention\n",
    "            else:\n",
    "                attention += layer_attention\n",
    "        # clean att score for <s> and </s>\n",
    "        attention = clean_special_token_values(attention, padding=True)\n",
    "        # attention should be 1D tensor with seq length representing each token's attention value\n",
    "        word_att_scores = get_word_att_scores(all_tokens=all_tokens, att_scores=attention)\n",
    "        all_lines_score, flaw_line_indices = get_all_lines_score(word_att_scores, verified_flaw_lines)\n",
    "        all_lines_score_with_label = \\\n",
    "        line_level_evaluation(all_lines_score=all_lines_score, flaw_line_indices=flaw_line_indices, top_k_loc=top_k_loc, top_k_constant=top_k_constant, true_positive_only=False)\n",
    "        \n",
    "        # <Nafis> Adding break for printing purposes\n",
    "        print(type(word_att_scores))\n",
    "        print(word_att_scores)\n",
    "        #break\n",
    "        \n",
    "        \n",
    "    elif reasoning_method == \"lig\":\n",
    "        ref_token_id, sep_token_id, cls_token_id = tokenizer.pad_token_id, tokenizer.sep_token_id, tokenizer.cls_token_id\n",
    "        ref_input_ids = create_ref_input_ids(input_ids, ref_token_id, sep_token_id, cls_token_id)\n",
    "        # send data to device\n",
    "        input_ids = input_ids.to(args.device)\n",
    "        labels = labels.to(args.device)\n",
    "        ref_input_ids = ref_input_ids.to(args.device)\n",
    "\n",
    "        lig = LayerIntegratedGradients(lig_forward, model.module.encoder.roberta.embeddings)\n",
    "\n",
    "        attributions, delta = lig.attribute(inputs=input_ids,\n",
    "                                            baselines=ref_input_ids,\n",
    "                                            internal_batch_size=32,\n",
    "                                            return_convergence_delta=True)\n",
    "        score = predict(input_ids)\n",
    "        pred_idx = torch.argmax(score).cpu().numpy()\n",
    "        pred_prob = score[pred_idx]\n",
    "        attributions_sum = summarize_attributions(attributions)        \n",
    "        attr_scores = attributions_sum.tolist()\n",
    "        # each token should have one score\n",
    "        assert len(all_tokens) == len(attr_scores)\n",
    "        # store tokens and attr scores together in a list of tuple [(token, attr_score)]\n",
    "        word_attr_scores = get_word_att_scores(all_tokens=all_tokens, att_scores=attr_scores)\n",
    "        # remove <s>, </s>, <unk>, <pad>\n",
    "        word_attr_scores = clean_word_attr_scores(word_attr_scores=word_attr_scores)\n",
    "        all_lines_score, flaw_line_indices = get_all_lines_score(word_attr_scores, verified_flaw_lines)\n",
    "        all_lines_score_with_label = \\\n",
    "        line_level_evaluation(all_lines_score=all_lines_score, flaw_line_indices=flaw_line_indices, top_k_loc=top_k_loc, top_k_constant=top_k_constant, true_positive_only=False)\n",
    "    elif reasoning_method == \"deeplift\" or \\\n",
    "            reasoning_method == \"deeplift_shap\" or \\\n",
    "            reasoning_method == \"gradient_shap\" or \\\n",
    "            reasoning_method == \"saliency\":\n",
    "        # send data to device\n",
    "        input_ids = input_ids.to(args.device)\n",
    "        input_embed = model.module.encoder.roberta.embeddings(input_ids).to(args.device)\n",
    "        if reasoning_method == \"deeplift\":\n",
    "            #baselines = torch.randn(1, 512, 768, requires_grad=True).to(args.device)\n",
    "            baselines = torch.zeros(1, 512, 768, requires_grad=True).to(args.device)\n",
    "            reasoning_model = DeepLift(model)\n",
    "        elif reasoning_method == \"deeplift_shap\":\n",
    "            #baselines = torch.randn(16, 512, 768, requires_grad=True).to(args.device)\n",
    "            baselines = torch.zeros(16, 512, 768, requires_grad=True).to(args.device)\n",
    "            reasoning_model = DeepLiftShap(model)\n",
    "        elif reasoning_method == \"gradient_shap\":\n",
    "            #baselines = torch.randn(16, 512, 768, requires_grad=True).to(args.device)\n",
    "            baselines = torch.zeros(16, 512, 768, requires_grad=True).to(args.device)\n",
    "            reasoning_model = GradientShap(model)\n",
    "        elif reasoning_method == \"saliency\":\n",
    "            reasoning_model = Saliency(model)\n",
    "        # attributions -> [1, 512, 768]\n",
    "        if reasoning_method == \"saliency\":\n",
    "            attributions = reasoning_model.attribute(input_embed, target=1)\n",
    "        else:\n",
    "            attributions = reasoning_model.attribute(input_embed, baselines=baselines, target=1)\n",
    "        attributions_sum = summarize_attributions(attributions)        \n",
    "        attr_scores = attributions_sum.tolist()\n",
    "        # each token should have one score\n",
    "        assert len(all_tokens) == len(attr_scores)\n",
    "        # store tokens and attr scores together in a list of tuple [(token, attr_score)]\n",
    "        word_attr_scores = get_word_att_scores(all_tokens=all_tokens, att_scores=attr_scores)\n",
    "        # remove <s>, </s>, <unk>, <pad>\n",
    "        word_attr_scores = clean_word_attr_scores(word_attr_scores=word_attr_scores)\n",
    "        all_lines_score, flaw_line_indices = get_all_lines_score(word_attr_scores, verified_flaw_lines)\n",
    "\n",
    "        all_lines_score_with_label = \\\n",
    "        line_level_evaluation(all_lines_score=all_lines_score, flaw_line_indices=flaw_line_indices, top_k_loc=top_k_loc, top_k_constant=top_k_constant, true_positive_only=False)        \n",
    "    return all_lines_score_with_label\n",
    "\n",
    "def line_level_evaluation(all_lines_score: list, flaw_line_indices: list, top_k_loc: list, top_k_constant: list, true_positive_only: bool, index=None):\n",
    "    if true_positive_only:    \n",
    "        # line indices ranking based on attr values \n",
    "        ranking = sorted(range(len(all_lines_score)), key=lambda i: all_lines_score[i], reverse=True)\n",
    "        # total flaw lines\n",
    "        num_of_flaw_lines = len(flaw_line_indices)\n",
    "        # clean lines + flaw lines\n",
    "        total_lines = len(all_lines_score)\n",
    "        ### TopK% Recall ###\n",
    "        all_correctly_predicted_flaw_lines = []  \n",
    "        ### IFA ###\n",
    "        ifa = True\n",
    "        all_clean_lines_inspected = []\n",
    "        for top_k in top_k_loc:\n",
    "            correctly_predicted_flaw_lines = 0\n",
    "            for indice in flaw_line_indices:\n",
    "                # if within top-k\n",
    "                k = int(len(all_lines_score) * top_k)\n",
    "                # if detecting any flaw lines\n",
    "                if indice in ranking[: k]:\n",
    "                    correctly_predicted_flaw_lines += 1\n",
    "                if ifa:\n",
    "                    # calculate Initial False Alarm\n",
    "                    # IFA counts how many clean lines are inspected until the first vulnerable line is found when inspecting the lines ranked by the approaches.\n",
    "                    flaw_line_idx_in_ranking = ranking.index(indice)\n",
    "                    # e.g. flaw_line_idx_in_ranking = 3 will include 1 vulnerable line and 3 clean lines\n",
    "                    all_clean_lines_inspected.append(flaw_line_idx_in_ranking)  \n",
    "            # for IFA\n",
    "            min_clean_lines_inspected = min(all_clean_lines_inspected)\n",
    "            # for All Effort\n",
    "            max_clean_lines_inspected = max(all_clean_lines_inspected)\n",
    "            # only do IFA and All Effort once\n",
    "            ifa = False\n",
    "            # append result for one top-k value\n",
    "            all_correctly_predicted_flaw_lines.append(correctly_predicted_flaw_lines)\n",
    "        \n",
    "        ### Top10 Accuracy ###\n",
    "        all_correctly_localized_func = []\n",
    "        top_10_correct_idx = []\n",
    "        top_10_not_correct_idx = []\n",
    "        correctly_located = False\n",
    "        for k in top_k_constant:\n",
    "            for indice in flaw_line_indices:\n",
    "                # if detecting any flaw lines\n",
    "                if indice in ranking[: k]:\n",
    "                    \"\"\"\n",
    "                    # extract example for the paper\n",
    "                    if index == 2797:\n",
    "                        print(\"2797\")\n",
    "                        print(\"ground truth flaw line index: \", indice)\n",
    "                        print(\"ranked line\")\n",
    "                        print(ranking)\n",
    "                        print(\"original score\")\n",
    "                        print(all_lines_score)\n",
    "                    \"\"\"\n",
    "                    # append result for one top-k value\n",
    "                    all_correctly_localized_func.append(1)\n",
    "                    correctly_located = True\n",
    "                else:\n",
    "                    all_correctly_localized_func.append(0)\n",
    "            if correctly_located:\n",
    "                top_10_correct_idx.append(index)\n",
    "            else:\n",
    "                top_10_not_correct_idx.append(index)\n",
    "        return total_lines, num_of_flaw_lines, all_correctly_predicted_flaw_lines, min_clean_lines_inspected, max_clean_lines_inspected, all_correctly_localized_func, \\\n",
    "               top_10_correct_idx, top_10_not_correct_idx\n",
    "    else:\n",
    "        # all_lines_score_with_label: [[line score, line level label], [line score, line level label], ...]\n",
    "        all_lines_score_with_label = []\n",
    "        for i in range(len(all_lines_score)):\n",
    "            if i in flaw_line_indices:\n",
    "                all_lines_score_with_label.append([all_lines_score[i], 1])\n",
    "            else:\n",
    "                all_lines_score_with_label.append([all_lines_score[i], 0])\n",
    "        return all_lines_score_with_label\n",
    "    \n",
    "def clean_special_token_values(all_values, padding=False):\n",
    "    # special token in the beginning of the seq \n",
    "    all_values[0] = 0\n",
    "    if padding:\n",
    "        # get the last non-zero value which represents the att score for </s> token\n",
    "        idx = [index for index, item in enumerate(all_values) if item != 0][-1]\n",
    "        all_values[idx] = 0\n",
    "    else:\n",
    "        # special token in the end of the seq \n",
    "        all_values[-1] = 0\n",
    "    return all_values\n",
    "\n",
    "def clean_shap_tokens(all_tokens):\n",
    "    for i in range(len(all_tokens)):\n",
    "        all_tokens[i] = all_tokens[i].replace('', '')\n",
    "    return all_tokens\n",
    "\n",
    "def get_all_lines_score(word_att_scores: list, verified_flaw_lines: list):\n",
    "    verified_flaw_lines = [''.join(l) for l in verified_flaw_lines]\n",
    "    # word_att_scores -> [[token, att_value], [token, att_value], ...]\n",
    "    separator = [\"\", \" \", \"\", \" \"]\n",
    "    # to return\n",
    "    all_lines_score = []\n",
    "    score_sum = 0\n",
    "    line_idx = 0\n",
    "    flaw_line_indices = []\n",
    "    line = \"\"\n",
    "    for i in range(len(word_att_scores)):\n",
    "        # summerize if meet line separator or the last token\n",
    "        if ((word_att_scores[i][0] in separator) or (i == (len(word_att_scores) - 1))) and score_sum != 0:\n",
    "            score_sum += word_att_scores[i][1]\n",
    "            all_lines_score.append(score_sum)\n",
    "            is_flaw_line = False\n",
    "            for l in verified_flaw_lines:\n",
    "                if l == line:\n",
    "                    is_flaw_line = True\n",
    "            if is_flaw_line:\n",
    "                flaw_line_indices.append(line_idx)\n",
    "            line = \"\"\n",
    "            score_sum = 0\n",
    "            line_idx += 1\n",
    "        # else accumulate score\n",
    "        elif word_att_scores[i][0] not in separator:\n",
    "            line += word_att_scores[i][0]\n",
    "            score_sum += word_att_scores[i][1]\n",
    "    return all_lines_score, flaw_line_indices\n",
    "\n",
    "def get_all_flaw_lines(flaw_lines: str, flaw_line_seperator: str) -> list:\n",
    "    if isinstance(flaw_lines, str):\n",
    "        flaw_lines = flaw_lines.strip(flaw_line_seperator)\n",
    "        flaw_lines = flaw_lines.split(flaw_line_seperator)\n",
    "        flaw_lines = [line.strip() for line in flaw_lines]\n",
    "    else:\n",
    "        flaw_lines = []\n",
    "    return flaw_lines\n",
    "\n",
    "def encode_all_lines(all_lines: list, tokenizer) -> list:\n",
    "    encoded = []\n",
    "    for line in all_lines:\n",
    "        encoded.append(encode_one_line(line=line, tokenizer=tokenizer))\n",
    "    return encoded\n",
    "\n",
    "def get_word_att_scores(all_tokens: list, att_scores: list) -> list:\n",
    "    word_att_scores = []\n",
    "    for i in range(len(all_tokens)):\n",
    "        token, att_score = all_tokens[i], att_scores[i]\n",
    "        word_att_scores.append([token, att_score])\n",
    "    return word_att_scores\n",
    "\n",
    "def clean_word_attr_scores(word_attr_scores: list) -> list:\n",
    "    to_be_cleaned = ['<s>', '</s>', '<unk>', '<pad>']\n",
    "    cleaned = []\n",
    "    for word_attr_score in word_attr_scores:\n",
    "        if word_attr_score[0] not in to_be_cleaned:\n",
    "            cleaned.append(word_attr_score)\n",
    "    return cleaned\n",
    "    \n",
    "def encode_one_line(line, tokenizer):\n",
    "    # add \"@ \" at the beginning to ensure the encoding consistency, i.e., previous -> previous, not previous > pre + vious\n",
    "    code_tokens = tokenizer.tokenize(\"@ \" + line)\n",
    "    return [token.replace(\"\", \"\") for token in code_tokens if token != \"@\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "463cbf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(args, model, tokenizer, test_dataset, best_threshold=0.5):\n",
    "    # build dataloader\n",
    "    test_sampler = SequentialSampler(test_dataset)\n",
    "    test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=args.eval_batch_size, num_workers=0)\n",
    "\n",
    "    # multi-gpu evaluate\n",
    "    if args.n_gpu > 1:\n",
    "        model = torch.nn.DataParallel(model)\n",
    "\n",
    "    # Eval!\n",
    "    logger.info(\"***** Running Test *****\")\n",
    "    logger.info(\"***** args.do_sorting_by_line_scores: *****\", args.do_sorting_by_line_scores)\n",
    "    logger.info(\"  Num examples = %d\", len(test_dataset))\n",
    "    logger.info(\"  Batch size = %d\", args.eval_batch_size)\n",
    "    eval_loss = 0.0\n",
    "    nb_eval_steps = 0\n",
    "    model.eval()\n",
    "    logits=[]  \n",
    "    y_trues=[]\n",
    "    \n",
    "    # For line level evaluation: Nafis\n",
    "    y_lines_true = []\n",
    "    locLogits = []\n",
    "\n",
    "    for batch in test_dataloader:\n",
    "        (inputs_ids, labels) = [x.to(args.device) for x in batch]\n",
    "        with torch.no_grad():\n",
    "            lm_loss, logit = model(input_ids=inputs_ids, labels=labels)\n",
    "            eval_loss += lm_loss.mean().item()\n",
    "            logits.append(logit.cpu().numpy())\n",
    "            y_trues.append(labels.cpu().numpy())\n",
    "        nb_eval_steps += 1\n",
    "    # calculate scores\n",
    "    logits = np.concatenate(logits, 0)\n",
    "    y_trues = np.concatenate(y_trues, 0)\n",
    "    y_preds = logits[:, 1] > best_threshold\n",
    "    acc = accuracy_score(y_trues, y_preds)\n",
    "    recall = recall_score(y_trues, y_preds)\n",
    "    precision = precision_score(y_trues, y_preds)   \n",
    "    f1 = f1_score(y_trues, y_preds)             \n",
    "    result = {\n",
    "        \"test_accuracy\": float(acc),\n",
    "        \"test_recall\": float(recall),\n",
    "        \"test_precision\": float(precision),\n",
    "        \"test_f1\": float(f1),\n",
    "        \"test_threshold\":best_threshold,\n",
    "    }\n",
    "\n",
    "    logger.info(\"***** Test results *****\")\n",
    "    for key in sorted(result.keys()):\n",
    "        logger.info(\"  %s = %s\", key, str(round(result[key],4)))\n",
    "\n",
    "    logits = [l[1] for l in logits]\n",
    "    result_df = generate_result_df(logits, y_trues, y_preds, args)\n",
    "    sum_lines, sum_flaw_lines = get_line_statistics(result_df)\n",
    "    \n",
    "    # write raw predictions if needed\n",
    "    if args.write_raw_preds:\n",
    "        write_raw_preds_csv(args, y_preds)\n",
    "\n",
    "\n",
    "\n",
    "    # define reasoning method\n",
    "    if args.reasoning_method == \"all\":\n",
    "            all_reasoning_method = [\"attention\", \"deeplift_shap\", \"saliency\", \"lig\", \"deeplift\", \"gradient_shap\"]\n",
    "    else:\n",
    "        all_reasoning_method = [args.reasoning_method]\n",
    "\n",
    "    if args.do_sorting_by_line_scores:\n",
    "        print(\"NAFIS: Sorting by line scores ...........\")\n",
    "        # (RQ2) Effort@TopK%Recall & Recall@TopK%LOC for the whole test set\n",
    "        # flatten the logits\n",
    "        for reasoning_method in all_reasoning_method:\n",
    "            dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=1, num_workers=0)\n",
    "            progress_bar = tqdm(dataloader, total=len(dataloader))\n",
    "            all_pos_score_label = []\n",
    "            all_neg_score_label = []\n",
    "            index = 0\n",
    "            total_pred_as_vul = 0\n",
    "            for mini_batch in progress_bar:\n",
    "                # if predicted as vulnerable\n",
    "                if result_df[\"logits\"][index] > 0.5:\n",
    "                    total_pred_as_vul += 1\n",
    "                    all_lines_score_with_label = \\\n",
    "                    line_level_localization(flaw_lines=result_df[\"flaw_line\"][index],\n",
    "                                            tokenizer=tokenizer, \n",
    "                                            model=model, \n",
    "                                            mini_batch=mini_batch, \n",
    "                                            original_func=result_df[\"processed_func\"][index], \n",
    "                                            args=args,\n",
    "                                            top_k_loc=None,\n",
    "                                            top_k_constant=None,\n",
    "                                            reasoning_method=reasoning_method,\n",
    "                                            index=index)\n",
    "                    all_pos_score_label.append(all_lines_score_with_label)\n",
    "                # else predicted as non vulnerable\n",
    "                else:\n",
    "                    all_lines_score_with_label = \\\n",
    "                    line_level_localization(flaw_lines=result_df[\"flaw_line\"][index],\n",
    "                                            tokenizer=tokenizer, \n",
    "                                            model=model, \n",
    "                                            mini_batch=mini_batch, \n",
    "                                            original_func=result_df[\"processed_func\"][index], \n",
    "                                            args=args,\n",
    "                                            top_k_loc=None,\n",
    "                                            top_k_constant=None,\n",
    "                                            reasoning_method=reasoning_method,\n",
    "                                            index=index)\n",
    "                    all_neg_score_label.append(all_lines_score_with_label)\n",
    "                index += 1\n",
    "            is_attention = True if reasoning_method == \"attention\" else False            \n",
    "            total_pos_lines, pos_rank_df  = rank_lines(all_pos_score_label, is_attention, ascending_ranking=False)\n",
    "            \n",
    "            if is_attention:\n",
    "                total_neg_lines, neg_rank_df  = rank_lines(all_neg_score_label, is_attention, ascending_ranking=True)\n",
    "            else:\n",
    "                total_neg_lines, neg_rank_df  = rank_lines(all_neg_score_label, is_attention, ascending_ranking=False)\n",
    "            \n",
    "            effort, inspected_line = top_k_effort(pos_rank_df, sum_lines, sum_flaw_lines, args.effort_at_top_k)\n",
    "\n",
    "            recall_value = top_k_recall(pos_rank_df, neg_rank_df, sum_lines, sum_flaw_lines, args.top_k_recall_by_lines)\n",
    "\n",
    "            logger.info(f\"total functions predicted as vulnerable: {total_pred_as_vul}\")\n",
    "\n",
    "            to_write = \"\"\n",
    "\n",
    "            to_write += \"\\n\" + f\"Reasoning Method: {reasoning_method}\" + \"\\n\"\n",
    "\n",
    "            to_write += f\"total predicted vulnerable lines: {total_pos_lines}\" + \"\\n\"\n",
    "            logger.info(f\"total predicted vulnerable lines: {total_pos_lines}\")\n",
    "\n",
    "            to_write += f\"total lines: {sum_lines}\" + \"\\n\"\n",
    "            logger.info(f\"total lines: {sum_lines}\")\n",
    "            \n",
    "            to_write += f\"total flaw lines: {sum_flaw_lines}\" + \"\\n\"\n",
    "            logger.info(f\"total flaw lines: {sum_flaw_lines}\")\n",
    "            \n",
    "            vul_as_vul = sum(pos_rank_df[\"label\"].tolist())\n",
    "            to_write += f\"total flaw lines in predicted as vulnerable: {vul_as_vul}\" + \"\\n\"\n",
    "            logger.info(f\"total flaw lines in predicted as vulnerable: {vul_as_vul}\")\n",
    "            \n",
    "            to_write += f\"top{args.effort_at_top_k}-Effort: {effort}\" + \"\\n\"\n",
    "            logger.info(f\"top{args.effort_at_top_k}-Effort: {effort}\")\n",
    "            \n",
    "            to_write += f\"total inspected line to find out {args.effort_at_top_k} of flaw lines: {inspected_line}\" + \"\\n\"\n",
    "            logger.info(f\"total inspected line to find out {args.effort_at_top_k} of flaw lines: {inspected_line}\")\n",
    "            \n",
    "            to_write += f\"top{args.top_k_recall_by_lines}-Recall: {recall_value}\" + \"\\n\"\n",
    "            logger.info(f\"top{args.top_k_recall_by_lines}-Recall: {recall_value}\")\n",
    "            \n",
    "            with open(\"./results/rq2_result.txt\", \"a\") as f:\n",
    "                f.write(to_write)\n",
    "\n",
    "    if args.do_sorting_by_pred_prob:\n",
    "        rank_df = rank_dataframe(df=result_df, rank_by=\"logits\", ascending=False)\n",
    "        effort, inspected_line = top_k_effort_pred_prob(rank_df, sum_lines, sum_flaw_lines, args.effort_at_top_k, label_col_name=\"y_preds\")\n",
    "        top_k_recall_val = top_k_recall_pred_prob(rank_df, sum_lines, sum_flaw_lines, args.top_k_recall_by_pred_prob, label_col_name=\"y_preds\")\n",
    "        with open(\"./results/rq2_result_pred_prob.txt\", \"a\") as f:\n",
    "            f.write(f\"\\n Sorted By Prediction Probabilities \\n top{args.effort_at_top_k}-Effort: {effort} \\n top{args.top_k_recall_by_pred_prob}-Recall: {top_k_recall_val}\")\n",
    "            logger.info(f\"\\n Sorted By Prediction Probabilities \\n top{args.effort_at_top_k}-Effort: {effort} \\n top{args.top_k_recall_by_pred_prob}-Recall: {top_k_recall_val}\")\n",
    "\n",
    "    # (RQ3) Line level evaluation for True Positive cases\n",
    "    if args.do_local_explanation:\n",
    "        for reasoning_method in all_reasoning_method:\n",
    "            logger.info(f\"***** Running Explanation - {reasoning_method} *****\")\n",
    "            correct_indices = np.where((y_trues == y_preds))\n",
    "            correct_indices = list(correct_indices[0])\n",
    "            print(\"correct prediction count: \", len(correct_indices))\n",
    "            tp_indices = np.where((y_trues == y_preds) & (y_trues == 1))\n",
    "            tp_indices = list(tp_indices[0])\n",
    "            print(\"correct vulnerable count: \", len(tp_indices))\n",
    "            # localization part\n",
    "            dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=1, num_workers=0)\n",
    "            # prepare data for line-level reasoning\n",
    "            df = pd.read_csv(args.test_data_file)\n",
    "            # stats for line-level evaluation\n",
    "            top_k_locs = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "            top_k_constant = [args.top_k_constant]\n",
    "            sum_total_lines = 0\n",
    "            total_flaw_lines = 0\n",
    "            total_function = 0\n",
    "            all_top_10_correct_idx = []\n",
    "            all_top_10_not_correct_idx = []\n",
    "            # for CodeBERT reasoning\n",
    "            total_correctly_predicted_flaw_lines = [0 for _ in range(len(top_k_locs))]\n",
    "            total_correctly_localized_function = [0 for _ in range(len(top_k_constant))]\n",
    "            total_min_clean_lines_inspected = 0\n",
    "            ifa_records = []\n",
    "            top_10_acc_records = []\n",
    "            total_max_clean_lines_inspected = 0\n",
    "            # vulnerability exist but not applicable (flaw tokens are out of seq length)\n",
    "            na_explanation_total = 0\n",
    "            na_eval_results_512 = 0\n",
    "            na_defective_data_point = 0\n",
    "            # track progress\n",
    "            progress_bar = tqdm(dataloader, total=len(dataloader))\n",
    "            # used to locate the row in test data\n",
    "            index = 0\n",
    "            for mini_batch in progress_bar:\n",
    "                # if true positive (vulnerable predicted as vulnerable), do explanation\n",
    "                if index in tp_indices:\n",
    "                    # if flaw line exists\n",
    "                    # if not exist, the data is as type of float (nan)\n",
    "                    if isinstance(df[\"flaw_line\"][index], str) and isinstance(df[\"flaw_line_index\"][index], str):                        \n",
    "                        line_eval_results = \\\n",
    "                        line_level_localization_tp(flaw_lines=df[\"flaw_line\"][index],\n",
    "                                                tokenizer=tokenizer, \n",
    "                                                model=model, \n",
    "                                                mini_batch=mini_batch, \n",
    "                                                original_func=df[\"processed_func\"][index], \n",
    "                                                args=args,\n",
    "                                                top_k_loc=top_k_locs,\n",
    "                                                top_k_constant=top_k_constant,\n",
    "                                                reasoning_method=reasoning_method,\n",
    "                                                index=index,\n",
    "                                                write_invalid_data=False)\n",
    "                        if line_eval_results == \"NA\":\n",
    "                            na_explanation_total += 1 \n",
    "                            na_eval_results_512 += 1\n",
    "                        else:                       \n",
    "                            total_function += 1\n",
    "                            sum_total_lines += line_eval_results[\"total_lines\"]\n",
    "                            total_flaw_lines += line_eval_results[\"num_of_flaw_lines\"]\n",
    "                            # IFA metric\n",
    "                            total_min_clean_lines_inspected += line_eval_results[\"min_clean_lines_inspected\"]\n",
    "                            \n",
    "                            # For IFA Boxplot\n",
    "                            ifa_records.append(line_eval_results[\"min_clean_lines_inspected\"])\n",
    "                            \n",
    "                            # For Top-10 Acc Boxplot\n",
    "                            # todo\n",
    "                            #top_10_acc_records.append(line_eval_results[]) \n",
    "                            \n",
    "                            # All effort metric\n",
    "                            total_max_clean_lines_inspected += line_eval_results[\"max_clean_lines_inspected\"]\n",
    "                            for j in range(len(top_k_locs)):\n",
    "                                total_correctly_predicted_flaw_lines[j] += line_eval_results[\"all_correctly_predicted_flaw_lines\"][j]\n",
    "                            # top 10 accuracy\n",
    "                            for k in range(len(top_k_constant)):\n",
    "                                total_correctly_localized_function[k] += line_eval_results[\"all_correctly_localized_function\"][k]\n",
    "                            # top 10 correct idx and not correct idx\n",
    "                            if line_eval_results[\"top_10_correct_idx\"] != []:\n",
    "                                all_top_10_correct_idx.append(line_eval_results[\"top_10_correct_idx\"][0])\n",
    "                            if line_eval_results[\"top_10_not_correct_idx\"] != []:\n",
    "                                all_top_10_not_correct_idx.append(line_eval_results[\"top_10_not_correct_idx\"][0]) \n",
    "                    else:\n",
    "                        na_explanation_total += 1\n",
    "                        na_defective_data_point += 1\n",
    "                index += 1\n",
    "\n",
    "            # write IFA records for IFA Boxplot\n",
    "            with open(f\"./ifa_records/ifa_{reasoning_method}.txt\", \"w+\") as f:\n",
    "                f.write(str(ifa_records))\n",
    "            # write Top-10 Acc records for Top-10 Accuracy Boxplot\n",
    "            # todo\n",
    "            #with open(f\"./top_10_acc_records/top_10_acc_{reasoning_method}.txt\", \"w+\") as f:\n",
    "            #    f.write(str())\n",
    "\n",
    "            logger.info(f\"Total number of functions: {total_function}\")\n",
    "            logger.info(f\"Total number of lines: {sum_total_lines}\")\n",
    "            logger.info(f\"Total number of flaw lines: {total_flaw_lines}\")\n",
    "            logger.info(f\"Total Explanation Not Applicable: {na_explanation_total}\")\n",
    "            logger.info(f\"NA Eval Results (Out of 512 Tokens): {na_eval_results_512}\")\n",
    "            logger.info(f\"NA Defective Data Point: {na_defective_data_point}\")\n",
    "\n",
    "            line_level_results = [{f\"codebert_{reasoning_method}_top20%_recall\": \n",
    "                                [round(total_correctly_predicted_flaw_lines[i] / total_flaw_lines, 2) * 100 for i in range(len(top_k_locs))],\n",
    "                                f\"codebert_{reasoning_method}_top10_accuracy\":\n",
    "                                [round(total_correctly_localized_function[i] / total_function, 2) * 100 for i in range(len(top_k_constant))],\n",
    "                                f\"codebert_{reasoning_method}_ifa\": \n",
    "                                round(total_min_clean_lines_inspected / total_function, 2),\n",
    "                                f\"codebert_{reasoning_method}_recall@topk%loc_auc\":\n",
    "                                auc(x=top_k_locs, y=[round(total_correctly_predicted_flaw_lines[i] / total_flaw_lines, 2) for i in range(len(top_k_locs))]),\n",
    "                                f\"codebert_{reasoning_method}_total_effort\":\n",
    "                                round(total_max_clean_lines_inspected / sum_total_lines, 2),\n",
    "                                \"avg_line_in_one_func\": \n",
    "                                int(sum_total_lines / total_function),\n",
    "                                \"total_func\": \n",
    "                                total_function,\n",
    "                                \"all_top_10_correct_idx\": all_top_10_correct_idx,\n",
    "                                \"all_top_10_not_correct_idx\": all_top_10_not_correct_idx}]\n",
    "                                \n",
    "            with open('./results/line_level_correct_idx.pkl', 'wb') as f:\n",
    "                pickle.dump(all_top_10_correct_idx, f)\n",
    "            with open('./results/line_level_not_correct_idx.pkl', 'wb') as f:\n",
    "                pickle.dump(all_top_10_not_correct_idx, f)\n",
    "\n",
    "            logger.info(\"***** Line Level Result *****\")\n",
    "            logger.info(line_level_results)\n",
    "            # output results\n",
    "            # with open(\"./results/local_explanation.pkl\", \"wb\") as f:\n",
    "            #    pickle.dump(line_level_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f2512c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 18864/18864 [00:20<00:00, 924.19it/s] \n",
      "12/05/2022 17:14:14 - INFO - __main__ -   ***** Running Test *****\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nafis/anaconda3/lib/python3.8/logging/__init__.py\", line 1081, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/home/nafis/anaconda3/lib/python3.8/logging/__init__.py\", line 925, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/home/nafis/anaconda3/lib/python3.8/logging/__init__.py\", line 664, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/home/nafis/anaconda3/lib/python3.8/logging/__init__.py\", line 369, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/home/nafis/anaconda3/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/home/nafis/anaconda3/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/nafis/anaconda3/lib/python3.8/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/nafis/anaconda3/lib/python3.8/site-packages/traitlets/config/application.py\", line 845, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/nafis/anaconda3/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 612, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/nafis/anaconda3/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/home/nafis/anaconda3/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/home/nafis/anaconda3/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n",
      "    handle._run()\n",
      "  File \"/home/nafis/anaconda3/lib/python3.8/asyncio/events.py\", line 81, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/home/nafis/anaconda3/lib/python3.8/site-packages/tornado/ioloop.py\", line 688, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"/home/nafis/anaconda3/lib/python3.8/site-packages/tornado/ioloop.py\", line 741, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/home/nafis/anaconda3/lib/python3.8/site-packages/tornado/gen.py\", line 814, in inner\n",
      "    self.ctx_run(self.run)\n",
      "  File \"/home/nafis/anaconda3/lib/python3.8/site-packages/tornado/gen.py\", line 775, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/home/nafis/anaconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/home/nafis/anaconda3/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n",
      "    yielded = ctx_run(next, result)\n",
      "  File \"/home/nafis/anaconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/home/nafis/anaconda3/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n",
      "    yielded = ctx_run(next, result)\n",
      "  File \"/home/nafis/anaconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 543, in execute_request\n",
      "    self.do_execute(\n",
      "  File \"/home/nafis/anaconda3/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n",
      "    yielded = ctx_run(next, result)\n",
      "  File \"/home/nafis/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 306, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/home/nafis/anaconda3/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/home/nafis/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2894, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/home/nafis/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2940, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/home/nafis/anaconda3/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/home/nafis/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3165, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/home/nafis/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3357, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/home/nafis/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3437, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-9-351104cbd37a>\", line 7, in <module>\n",
      "    test(args, model, tokenizer, test_dataset, best_threshold=0.5)\n",
      "  File \"<ipython-input-8-99a2ab295da5>\", line 12, in test\n",
      "    logger.info(\"***** args.do_sorting_by_line_scores: *****\", args.do_sorting_by_line_scores)\n",
      "Message: '***** args.do_sorting_by_line_scores: *****'\n",
      "Arguments: (True,)\n",
      "12/05/2022 17:14:14 - INFO - __main__ -     Num examples = 18864\n",
      "12/05/2022 17:14:14 - INFO - __main__ -     Batch size = 256\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Caught AttributeError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/home/nafis/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py\", line 61, in _worker\n    output = module(*input, **kwargs)\n  File \"/home/nafis/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/nafis/Development/LineVul/linevul/linevul_model.py\", line 98, in forward\n    loss = loss_mse(localizerLogits, lines.float())\nAttributeError: 'NoneType' object has no attribute 'float'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-351104cbd37a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"This is a test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-99a2ab295da5>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(args, model, tokenizer, test_dataset, best_threshold)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0minputs_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mlm_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0meval_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlm_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;31m# instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Caught AttributeError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/home/nafis/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py\", line 61, in _worker\n    output = module(*input, **kwargs)\n  File \"/home/nafis/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/nafis/Development/LineVul/linevul/linevul_model.py\", line 98, in forward\n    loss = loss_mse(localizerLogits, lines.float())\nAttributeError: 'NoneType' object has no attribute 'float'\n"
     ]
    }
   ],
   "source": [
    "checkpoint_prefix = f'checkpoint-best-IoU/{args.model_name}'\n",
    "output_dir = os.path.join(args.output_dir, '{}'.format(checkpoint_prefix))  \n",
    "model.load_state_dict(torch.load(output_dir, map_location=args.device))\n",
    "model.to(args.device)\n",
    "print(\"This is a test\")\n",
    "test_dataset = TextDataset(tokenizer, args, file_type='test')\n",
    "test(args, model, tokenizer, test_dataset, best_threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af9abe9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
